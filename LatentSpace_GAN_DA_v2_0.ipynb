{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 4458388,
          "sourceType": "datasetVersion",
          "datasetId": 2609958
        }
      ],
      "dockerImageVersionId": 30775,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Downloadin' the Dataset from Kaggle"
      ],
      "metadata": {
        "id": "5Ft4zbHWLd32"
      }
    },
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'home-office-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2609958%2F4458388%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240929%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240929T182135Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6335ea9becd6a8fb3ab0ee0f2a593cf71061fe87419776bd67aded05e4a070c929bd28c43a5baa78975f162afc2e1962d2957365a93b663e4983d784677fb7d2c002a4749470c319251673796792bc26d5f46400067981cce63a149b1ff4e1fdecba4c1442d65f04177410e97fbc0fbe2dd89217eeda0cd63a60446a971513b346b08829770702afc0bb01f817fb9fe3a06cf13ba9f1422478d90e1df6f4a44494a013a581eb375f419753f3c006cd2538214b4b65ab5fae37f0f7a0a649eba61920fe96573f68eb29d36102f3a194508fd9b8d52c69be90697ed6630e7233b8994ab4761c899cf23a0598b9156c7f5949e6421f297bf3d2888b8a5629a4882b'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL4hxQ92BFxX",
        "outputId": "708e79b4-7250-48b8-ad93-3690b4458c37"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading home-office-dataset, 1030224236 bytes compressed\n",
            "[==================================================] 1030224236 bytes downloaded\n",
            "Downloaded and uncompressed: home-office-dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary Imports"
      ],
      "metadata": {
        "id": "TKD7E63LLm8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T18:11:30.971373Z",
          "iopub.execute_input": "2024-09-29T18:11:30.972138Z",
          "iopub.status.idle": "2024-09-29T18:11:47.04981Z",
          "shell.execute_reply.started": "2024-09-29T18:11:30.972086Z",
          "shell.execute_reply": "2024-09-29T18:11:47.048049Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr3aGOI2BFxo",
        "outputId": "98eef975-8293-4f30-a74b-dff818dc51e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T18:11:15.197773Z",
          "iopub.execute_input": "2024-09-29T18:11:15.198846Z",
          "iopub.status.idle": "2024-09-29T18:11:30.969133Z",
          "shell.execute_reply.started": "2024-09-29T18:11:15.198791Z",
          "shell.execute_reply": "2024-09-29T18:11:30.967803Z"
        },
        "trusted": true,
        "id": "XD1tXdZ_BFxp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator Block"
      ],
      "metadata": {
        "id": "4y9Gy3CcGi6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # Input: 3 channels (RGB), 64x64 -> 32x32\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 32x32 -> 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 16x16 -> 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # 8x8 -> 4x4\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, latent_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "w4AtrFutBfky"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator Block"
      ],
      "metadata": {
        "id": "hzP84kAcGpNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, latent_dim=100):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.network(z)"
      ],
      "metadata": {
        "id": "AYdiWzkFGsUx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder (Debo Bhai)"
      ],
      "metadata": {
        "id": "S48M4-wTG7UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=100):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256 * 4 * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (256, 4, 4)),\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),\n",
        "            nn.Tanh()  # Output between [-1, 1]\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        return self.decode(z)"
      ],
      "metadata": {
        "id": "7KGvIWmkBYD0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss functions"
      ],
      "metadata": {
        "id": "5VO1YL3BHGVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = nn.BCELoss()  # Binary Cross-Entropy for adversarial loss\n",
        "reconstruction_loss = nn.MSELoss()  # MSE for reconstruction"
      ],
      "metadata": {
        "id": "ORcjuDZXBrNq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Init"
      ],
      "metadata": {
        "id": "D-w7ZPJsL7Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "generator = Generator(latent_dim)\n",
        "discriminator = Discriminator(latent_dim)\n",
        "autoencoder = Autoencoder(latent_dim)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=1e-3)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-3)\n",
        "optimizer_AE = optim.Adam(autoencoder.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "fo0DVJEHL9dU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Func (to compute accuracy)"
      ],
      "metadata": {
        "id": "P5rP0Y4rHY86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def compute_accuracy(preds, labels):\n",
        "    predicted = (preds > 0.5).float()\n",
        "    correct = (predicted == labels).float().sum()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "-wGYMQZbF8sp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Domain Classifier"
      ],
      "metadata": {
        "id": "tumny1GqHU6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DomainClassifier(nn.Module):\n",
        "    def __init__(self, latent_dim=100):\n",
        "        super(DomainClassifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.classifier(z)"
      ],
      "metadata": {
        "id": "Zb69fsxVF_Un"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DA (Hank?) Trainer"
      ],
      "metadata": {
        "id": "aDS-nz89Hu_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "data_dir_source = '/kaggle/input/home-office-dataset/OfficeHomeDataset_10072016/Art'\n",
        "data_dir_target = '/kaggle/input/home-office-dataset/OfficeHomeDataset_10072016/Clipart'\n",
        "\n",
        "dataset_source = datasets.ImageFolder(root=data_dir_source, transform=transform)\n",
        "dataset_target = datasets.ImageFolder(root=data_dir_target, transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "dataloader_source = DataLoader(dataset_source, batch_size=64, shuffle=True)\n",
        "dataloader_target = DataLoader(dataset_target, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "N7pE5oGoNKPw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan_domain_adaptation(dataloader_source, dataloader_target, n_epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "    autoencoder.to(device)\n",
        "    domain_classifier = DomainClassifier(latent_dim).to(device)  # init domain classifier\n",
        "\n",
        "    # optimizers\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=1e-3)\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-3)\n",
        "    optimizer_AE = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
        "    optimizer_DC = optim.Adam(domain_classifier.parameters(), lr=1e-3)  # optimizer for domain classifier\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        total_dc_loss = 0.0\n",
        "        total_d_loss = 0.0\n",
        "        total_g_loss = 0.0\n",
        "        total_ae_loss = 0.0\n",
        "        total_dc_accuracy = 0.0\n",
        "        total_batches = 0\n",
        "\n",
        "        loop = tqdm(zip(dataloader_source, dataloader_target), total=min(len(dataloader_source), len(dataloader_target)))\n",
        "        loop.set_description(f\"Epoch [{epoch+1}/{n_epochs}]\")\n",
        "\n",
        "        for (source_images, _), (target_images, _) in loop:\n",
        "            source_images = source_images.to(device)\n",
        "            target_images = target_images.to(device)\n",
        "\n",
        "            # for batch size consistency\n",
        "            min_batch_size = min(source_images.size(0), target_images.size(0))\n",
        "            source_images = source_images[:min_batch_size]\n",
        "            target_images = target_images[:min_batch_size]\n",
        "\n",
        "            # =======================\n",
        "            # 1. train the discriminator\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            target_latent_fake = generator(target_images)\n",
        "            source_latent_real = autoencoder.encode(source_images)  # real latent vectors from source\n",
        "\n",
        "            real_labels = torch.ones(min_batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(min_batch_size, 1).to(device)\n",
        "\n",
        "            # discriminator loss on real and fake\n",
        "            d_loss_real = adversarial_loss(discriminator(source_latent_real), real_labels)\n",
        "            d_loss_fake = adversarial_loss(discriminator(target_latent_fake.detach()), fake_labels)\n",
        "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # discriminator Accuracy (real vs fake)\n",
        "            real_accuracy = compute_accuracy(discriminator(source_latent_real), real_labels)\n",
        "            fake_accuracy = compute_accuracy(discriminator(target_latent_fake.detach()), fake_labels)\n",
        "            d_accuracy = (real_accuracy + fake_accuracy) / 2\n",
        "\n",
        "            # =======================\n",
        "            # 2. train the Generator\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            g_loss = adversarial_loss(discriminator(target_latent_fake), real_labels)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # =======================\n",
        "            # 3. train the autoencoder (for source domain reconstruction)\n",
        "\n",
        "            optimizer_AE.zero_grad()\n",
        "\n",
        "            source_reconstructed = autoencoder(source_images)  # reconstruct source images\n",
        "            ae_loss = reconstruction_loss(source_reconstructed, source_images)  # reconstruction loss\n",
        "            ae_loss.backward()\n",
        "            optimizer_AE.step()\n",
        "\n",
        "            # =======================\n",
        "            # 4. train the Domain Classifier\n",
        "\n",
        "            optimizer_DC.zero_grad()\n",
        "\n",
        "            # Domain classification: 0 for source, 1 for target\n",
        "            domain_labels_source = torch.zeros(min_batch_size, 1).to(device)\n",
        "            domain_labels_target = torch.ones(min_batch_size, 1).to(device)\n",
        "\n",
        "            # train domain classifier on both source and target latent vectors\n",
        "            domain_pred_source = domain_classifier(source_latent_real.detach())\n",
        "            domain_pred_target = domain_classifier(target_latent_fake.detach())\n",
        "\n",
        "            # domain classifier loss (BCE)\n",
        "            dc_loss_source = adversarial_loss(domain_pred_source, domain_labels_source)\n",
        "            dc_loss_target = adversarial_loss(domain_pred_target, domain_labels_target)\n",
        "            dc_loss = (dc_loss_source + dc_loss_target) / 2\n",
        "            dc_loss.backward()\n",
        "            optimizer_DC.step()\n",
        "\n",
        "            # domain classifier accuracy\n",
        "            dc_accuracy_source = compute_accuracy(domain_pred_source, domain_labels_source)\n",
        "            dc_accuracy_target = compute_accuracy(domain_pred_target, domain_labels_target)\n",
        "            dc_accuracy = (dc_accuracy_source + dc_accuracy_target) / 2\n",
        "\n",
        "            # accumulation of loss and accuracy\n",
        "            total_dc_loss += dc_loss.item()\n",
        "            total_d_loss += d_loss.item()\n",
        "            total_g_loss += g_loss.item()\n",
        "            total_ae_loss += ae_loss.item()\n",
        "            total_dc_accuracy += dc_accuracy.item()\n",
        "            total_batches += 1\n",
        "\n",
        "            loop.set_postfix(\n",
        "                D_loss=total_d_loss/total_batches,\n",
        "                G_loss=total_g_loss/total_batches,\n",
        "                AE_loss=total_ae_loss/total_batches,\n",
        "                DC_loss=total_dc_loss/total_batches,\n",
        "                DC_acc=total_dc_accuracy/total_batches\n",
        "            )\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}] Summary:\")\n",
        "        print(f\"  Discriminator Loss: {total_d_loss/total_batches:.4f}\")\n",
        "        print(f\"  Generator Loss: {total_g_loss/total_batches:.4f}\")\n",
        "        print(f\"  Autoencoder Loss: {total_ae_loss/total_batches:.4f}\")\n",
        "        print(f\"  Domain Classifier Loss: {total_dc_loss/total_batches:.4f}\")\n",
        "        print(f\"  Domain Classifier Accuracy: {total_dc_accuracy/total_batches:.4f}\")\n",
        "\n",
        "train_gan_domain_adaptation(dataloader_source, dataloader_target, n_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS3DFZ5yFoYD",
        "outputId": "dd6233ec-0f33-459a-d57d-4c20e8d9e807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/10]: 100%|██████████| 38/38 [01:17<00:00,  2.04s/it, AE_loss=0.142, DC_acc=0.981, DC_loss=0.198, D_loss=0.0571, G_loss=3.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Summary:\n",
            "  Discriminator Loss: 0.0571\n",
            "  Generator Loss: 3.5098\n",
            "  Autoencoder Loss: 0.1420\n",
            "  Domain Classifier Loss: 0.1980\n",
            "  Domain Classifier Accuracy: 0.9811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/10]: 100%|██████████| 38/38 [01:19<00:00,  2.09s/it, AE_loss=0.0919, DC_acc=1, DC_loss=0.0223, D_loss=0.02, G_loss=4.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10] Summary:\n",
            "  Discriminator Loss: 0.0200\n",
            "  Generator Loss: 4.1522\n",
            "  Autoencoder Loss: 0.0919\n",
            "  Domain Classifier Loss: 0.0223\n",
            "  Domain Classifier Accuracy: 0.9996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/10]: 100%|██████████| 38/38 [01:25<00:00,  2.25s/it, AE_loss=0.0876, DC_acc=0.999, DC_loss=0.0323, D_loss=0.0326, G_loss=4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10] Summary:\n",
            "  Discriminator Loss: 0.0326\n",
            "  Generator Loss: 3.9963\n",
            "  Autoencoder Loss: 0.0876\n",
            "  Domain Classifier Loss: 0.0323\n",
            "  Domain Classifier Accuracy: 0.9985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4/10]: 100%|██████████| 38/38 [01:21<00:00,  2.14s/it, AE_loss=0.0851, DC_acc=0.999, DC_loss=0.0121, D_loss=0.0138, G_loss=4.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10] Summary:\n",
            "  Discriminator Loss: 0.0138\n",
            "  Generator Loss: 4.6070\n",
            "  Autoencoder Loss: 0.0851\n",
            "  Domain Classifier Loss: 0.0121\n",
            "  Domain Classifier Accuracy: 0.9994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5/10]: 100%|██████████| 38/38 [01:18<00:00,  2.08s/it, AE_loss=0.0832, DC_acc=0.999, DC_loss=0.0121, D_loss=0.0146, G_loss=4.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10] Summary:\n",
            "  Discriminator Loss: 0.0146\n",
            "  Generator Loss: 4.3976\n",
            "  Autoencoder Loss: 0.0832\n",
            "  Domain Classifier Loss: 0.0121\n",
            "  Domain Classifier Accuracy: 0.9990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6/10]: 100%|██████████| 38/38 [01:22<00:00,  2.17s/it, AE_loss=0.0809, DC_acc=0.999, DC_loss=0.0152, D_loss=0.0131, G_loss=4.37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10] Summary:\n",
            "  Discriminator Loss: 0.0131\n",
            "  Generator Loss: 4.3682\n",
            "  Autoencoder Loss: 0.0809\n",
            "  Domain Classifier Loss: 0.0152\n",
            "  Domain Classifier Accuracy: 0.9992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [7/10]: 100%|██████████| 38/38 [01:23<00:00,  2.19s/it, AE_loss=0.0793, DC_acc=0.999, DC_loss=0.0143, D_loss=0.0122, G_loss=4.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10] Summary:\n",
            "  Discriminator Loss: 0.0122\n",
            "  Generator Loss: 4.1980\n",
            "  Autoencoder Loss: 0.0793\n",
            "  Domain Classifier Loss: 0.0143\n",
            "  Domain Classifier Accuracy: 0.9994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [8/10]: 100%|██████████| 38/38 [01:18<00:00,  2.07s/it, AE_loss=0.078, DC_acc=1, DC_loss=0.00685, D_loss=0.00653, G_loss=4.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10] Summary:\n",
            "  Discriminator Loss: 0.0065\n",
            "  Generator Loss: 4.9872\n",
            "  Autoencoder Loss: 0.0780\n",
            "  Domain Classifier Loss: 0.0068\n",
            "  Domain Classifier Accuracy: 0.9998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [9/10]: 100%|██████████| 38/38 [01:21<00:00,  2.14s/it, AE_loss=0.0768, DC_acc=0.999, DC_loss=0.00531, D_loss=0.00349, G_loss=5.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10] Summary:\n",
            "  Discriminator Loss: 0.0035\n",
            "  Generator Loss: 5.4977\n",
            "  Autoencoder Loss: 0.0768\n",
            "  Domain Classifier Loss: 0.0053\n",
            "  Domain Classifier Accuracy: 0.9994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10/10]: 100%|██████████| 38/38 [01:17<00:00,  2.05s/it, AE_loss=0.0751, DC_acc=1, DC_loss=0.00451, D_loss=0.00206, G_loss=6.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10] Summary:\n",
            "  Discriminator Loss: 0.0021\n",
            "  Generator Loss: 6.0477\n",
            "  Autoencoder Loss: 0.0751\n",
            "  Domain Classifier Loss: 0.0045\n",
            "  Domain Classifier Accuracy: 0.9996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V2.0 Starts"
      ],
      "metadata": {
        "id": "qo7bEc0B8KNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SourceClassifier(nn.Module):\n",
        "    def __init__(self, latent_dim=100, num_classes=10):\n",
        "        super(SourceClassifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.classifier(z)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "source_classifier = SourceClassifier(latent_dim=100, num_classes=10).to(device)\n",
        "source_criterion = nn.CrossEntropyLoss()\n",
        "optimizer_SC = optim.Adam(source_classifier.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "RoK06MRB8O5e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def train_source_classifier(dataloader_source, n_epochs=10):\n",
        "    autoencoder.eval()\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0\n",
        "        for source_images, source_labels in dataloader_source:\n",
        "            source_images = source_images.to(device)\n",
        "            source_labels = source_labels.to(device)\n",
        "\n",
        "            source_latent = autoencoder.encode(source_images)\n",
        "            output = source_classifier(source_latent)\n",
        "            source_labels = torch.clamp(source_labels, 0, source_classifier.classifier[-1].out_features - 1)\n",
        "\n",
        "            loss = source_criterion(output, source_labels)\n",
        "            optimizer_SC.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_SC.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {total_loss/len(dataloader_source):.4f}\")\n",
        "\n",
        "train_source_classifier(dataloader_source, n_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-S2SKZB8c20",
        "outputId": "736d3f91-3e51-493f-baec-200f2d98c5a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.2142\n",
            "Epoch [2/10], Loss: 1.2422\n",
            "Epoch [3/10], Loss: 0.8735\n",
            "Epoch [4/10], Loss: 0.8630\n",
            "Epoch [5/10], Loss: 0.8627\n",
            "Epoch [6/10], Loss: 0.8629\n",
            "Epoch [7/10], Loss: 0.8636\n",
            "Epoch [8/10], Loss: 0.8623\n",
            "Epoch [9/10], Loss: 0.8626\n",
            "Epoch [10/10], Loss: 0.8624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class DomainClassifier(nn.Module):\n",
        "    def __init__(self, latent_dim=100):\n",
        "        super(DomainClassifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.classifier(z)\n",
        "\n",
        "latent_dim = 100\n",
        "domain_classifier = DomainClassifier(latent_dim).to(device)\n",
        "\n",
        "adversarial_loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "BtvmsFXu-PvS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_domain_adaptation(dataloader_source, dataloader_target, n_epochs=10):\n",
        "    generator.to(device)\n",
        "    domain_classifier.to(device)\n",
        "\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=1e-3)\n",
        "    optimizer_DC = optim.Adam(domain_classifier.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for (source_images, _), (target_images, _) in zip(dataloader_source, dataloader_target):\n",
        "            source_images = source_images.to(device)\n",
        "            target_images = target_images.to(device)\n",
        "\n",
        "            min_batch_size = min(source_images.size(0), target_images.size(0))\n",
        "            source_images = source_images[:min_batch_size]\n",
        "            target_images = target_images[:min_batch_size]\n",
        "\n",
        "            source_latent = autoencoder.encode(source_images)\n",
        "            target_latent = generator(target_images)\n",
        "\n",
        "            # =======================\n",
        "            # 1. Train the Domain Classifier\n",
        "            optimizer_DC.zero_grad()\n",
        "\n",
        "            domain_labels_source = torch.zeros(min_batch_size, 1).to(device)  # Source: 0\n",
        "            domain_labels_target = torch.ones(min_batch_size, 1).to(device)   # Target: 1\n",
        "\n",
        "            domain_pred_source = domain_classifier(source_latent.detach())\n",
        "            domain_pred_target = domain_classifier(target_latent.detach())\n",
        "\n",
        "            dc_loss_source = adversarial_loss(domain_pred_source, domain_labels_source)\n",
        "            dc_loss_target = adversarial_loss(domain_pred_target, domain_labels_target)\n",
        "            dc_loss = (dc_loss_source + dc_loss_target) / 2\n",
        "\n",
        "            dc_loss.backward()\n",
        "            optimizer_DC.step()\n",
        "\n",
        "            # =======================\n",
        "            # 2. Train the Generator (to fool Domain Classifier)\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            domain_pred_target = domain_classifier(target_latent)\n",
        "            g_loss = adversarial_loss(domain_pred_target, domain_labels_source)\n",
        "\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], G_loss: {g_loss.item():.4f}, DC_loss: {dc_loss.item():.4f}\")\n",
        "\n",
        "# domain adaptation model\n",
        "train_domain_adaptation(dataloader_source, dataloader_target, n_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyHE9CWQ8erK",
        "outputId": "e68e80ce-02b3-42b1-a00d-8fd752d8920a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], G_loss: 0.6652, DC_loss: 0.6984\n",
            "Epoch [2/10], G_loss: 0.6735, DC_loss: 0.6996\n",
            "Epoch [3/10], G_loss: 0.6886, DC_loss: 0.6942\n",
            "Epoch [4/10], G_loss: 0.6953, DC_loss: 0.6872\n",
            "Epoch [5/10], G_loss: 0.6918, DC_loss: 0.6905\n",
            "Epoch [6/10], G_loss: 0.7172, DC_loss: 0.6833\n",
            "Epoch [7/10], G_loss: 0.7374, DC_loss: 0.6781\n",
            "Epoch [8/10], G_loss: 0.7051, DC_loss: 0.6814\n",
            "Epoch [9/10], G_loss: 0.7988, DC_loss: 0.6148\n",
            "Epoch [10/10], G_loss: 0.9068, DC_loss: 0.6001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_target(dataloader_target):\n",
        "    source_classifier.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for target_images, target_labels in dataloader_target:\n",
        "            target_images = target_images.to(device)\n",
        "            target_labels = target_labels.to(device)\n",
        "\n",
        "            target_latent = generator(target_images)\n",
        "            outputs = source_classifier(target_latent)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += target_labels.size(0)\n",
        "            correct += (predicted == target_labels).sum().item()\n",
        "\n",
        "    print(f\"Accuracy on target domain: {100 * correct / total:.2f}%\")\n",
        "\n",
        "evaluate_on_target(dataloader_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPs5TMOR8en3",
        "outputId": "12e54165-f8aa-4024-dac5-325269f4043e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on target domain: 2.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, latent_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, latent_dim=100):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.network(z)\n",
        "\n",
        "def compute_accuracy(preds, labels):\n",
        "    predicted = (preds > 0.5).float()\n",
        "    correct = (predicted == labels).float().sum()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy.item()\n",
        "\n",
        "def train_gan_domain_adaptation(dataloader_source, dataloader_target, n_epochs=10):\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=1e-3)\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-3)\n",
        "    adversarial_loss = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        total_d_loss = 0.0\n",
        "        total_g_loss = 0.0\n",
        "        total_accuracy = 0.0\n",
        "        total_batches = 0\n",
        "\n",
        "        loop = tqdm(zip(dataloader_source, dataloader_target), total=min(len(dataloader_source), len(dataloader_target)))\n",
        "        loop.set_description(f\"Epoch [{epoch+1}/{n_epochs}]\")\n",
        "\n",
        "        for (source_images, _), (target_images, _) in loop:\n",
        "            source_images = source_images.to(device)\n",
        "            target_images = target_images.to(device)\n",
        "\n",
        "            min_batch_size = min(source_images.size(0), target_images.size(0))\n",
        "            source_images = source_images[:min_batch_size]\n",
        "            target_images = target_images[:min_batch_size]\n",
        "\n",
        "            # =======================\n",
        "            # 1. Train the Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Generate latent vectors for the target domain using the Generator\n",
        "            target_latent_fake = generator(target_images)\n",
        "            source_latent_real = generator(source_images)\n",
        "\n",
        "            real_labels = torch.ones(min_batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(min_batch_size, 1).to(device)\n",
        "\n",
        "            d_loss_real = adversarial_loss(discriminator(source_latent_real), real_labels)\n",
        "            d_loss_fake = adversarial_loss(discriminator(target_latent_fake.detach()), fake_labels)\n",
        "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            real_accuracy = compute_accuracy(discriminator(source_latent_real), real_labels)\n",
        "            fake_accuracy = compute_accuracy(discriminator(target_latent_fake.detach()), fake_labels)\n",
        "            d_accuracy = (real_accuracy + fake_accuracy) / 2\n",
        "\n",
        "            # =======================\n",
        "            # 2. Train the Generator (to fool the Discriminator)\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            g_loss = adversarial_loss(discriminator(target_latent_fake), real_labels)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            total_d_loss += d_loss.item()\n",
        "            total_g_loss += g_loss.item()\n",
        "            total_accuracy += d_accuracy\n",
        "            total_batches += 1\n",
        "\n",
        "            loop.set_postfix(\n",
        "                D_loss=total_d_loss/total_batches,\n",
        "                G_loss=total_g_loss/total_batches,\n",
        "                D_accuracy=total_accuracy/total_batches\n",
        "            )\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}] Summary:\")\n",
        "        print(f\"  Discriminator Loss: {total_d_loss/total_batches:.4f}\")\n",
        "        print(f\"  Generator Loss: {total_g_loss/total_batches:.4f}\")\n",
        "        print(f\"  Discriminator Accuracy: {total_accuracy/total_batches:.4f}\")\n",
        "\n",
        "latent_dim = 100\n",
        "generator = Generator(latent_dim=latent_dim)\n",
        "discriminator = Discriminator(latent_dim=latent_dim)\n",
        "\n",
        "train_gan_domain_adaptation(dataloader_source, dataloader_target, n_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVrrIVbB8elx",
        "outputId": "c82cb4ba-f334-4f5d-92be-7b22853bd959"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/10]: 100%|██████████| 38/38 [00:55<00:00,  1.47s/it, D_accuracy=0.509, D_loss=2.89, G_loss=1.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Summary:\n",
            "  Discriminator Loss: 2.8905\n",
            "  Generator Loss: 1.1805\n",
            "  Discriminator Accuracy: 0.5093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/10]: 100%|██████████| 38/38 [00:56<00:00,  1.49s/it, D_accuracy=0.5, D_loss=0.693, G_loss=0.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10] Summary:\n",
            "  Discriminator Loss: 0.6933\n",
            "  Generator Loss: 0.6803\n",
            "  Discriminator Accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/10]: 100%|██████████| 38/38 [00:55<00:00,  1.47s/it, D_accuracy=0.501, D_loss=0.693, G_loss=0.693]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10] Summary:\n",
            "  Discriminator Loss: 0.6931\n",
            "  Generator Loss: 0.6931\n",
            "  Discriminator Accuracy: 0.5015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4/10]: 100%|██████████| 38/38 [00:55<00:00,  1.45s/it, D_accuracy=0.503, D_loss=0.693, G_loss=0.694]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10] Summary:\n",
            "  Discriminator Loss: 0.6931\n",
            "  Generator Loss: 0.6935\n",
            "  Discriminator Accuracy: 0.5031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5/10]: 100%|██████████| 38/38 [00:55<00:00,  1.46s/it, D_accuracy=0.501, D_loss=0.693, G_loss=0.694]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10] Summary:\n",
            "  Discriminator Loss: 0.6931\n",
            "  Generator Loss: 0.6938\n",
            "  Discriminator Accuracy: 0.5014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6/10]: 100%|██████████| 38/38 [00:55<00:00,  1.46s/it, D_accuracy=0.5, D_loss=0.693, G_loss=0.694]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10] Summary:\n",
            "  Discriminator Loss: 0.6931\n",
            "  Generator Loss: 0.6943\n",
            "  Discriminator Accuracy: 0.5002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [7/10]: 100%|██████████| 38/38 [00:56<00:00,  1.48s/it, D_accuracy=0.503, D_loss=0.693, G_loss=0.694]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10] Summary:\n",
            "  Discriminator Loss: 0.6931\n",
            "  Generator Loss: 0.6939\n",
            "  Discriminator Accuracy: 0.5029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [8/10]: 100%|██████████| 38/38 [00:55<00:00,  1.47s/it, D_accuracy=0.5, D_loss=0.693, G_loss=0.694]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10] Summary:\n",
            "  Discriminator Loss: 0.6931\n",
            "  Generator Loss: 0.6942\n",
            "  Discriminator Accuracy: 0.5004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [9/10]: 100%|██████████| 38/38 [00:55<00:00,  1.47s/it, D_accuracy=0.501, D_loss=0.693, G_loss=0.694]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10] Summary:\n",
            "  Discriminator Loss: 0.6931\n",
            "  Generator Loss: 0.6944\n",
            "  Discriminator Accuracy: 0.5009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10/10]: 100%|██████████| 38/38 [00:56<00:00,  1.49s/it, D_accuracy=0.5, D_loss=0.693, G_loss=0.695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10] Summary:\n",
            "  Discriminator Loss: 0.6931\n",
            "  Generator Loss: 0.6948\n",
            "  Discriminator Accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SourceClassifier(nn.Module):\n",
        "    def __init__(self, latent_dim=100, num_classes=10):\n",
        "        super(SourceClassifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.classifier(z)\n"
      ],
      "metadata": {
        "id": "qENHeZ_W8egn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_source_classifier(dataloader_source, n_epochs=10):\n",
        "    source_classifier.to(device)\n",
        "    generator.eval()\n",
        "\n",
        "    classification_loss = nn.CrossEntropyLoss()\n",
        "    optimizer_SC = optim.Adam(source_classifier.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        loop = tqdm(dataloader_source, total=len(dataloader_source))\n",
        "        loop.set_description(f\"Train Source Classifier - Epoch [{epoch+1}/{n_epochs}]\")\n",
        "\n",
        "        for source_images, source_labels in loop:\n",
        "            source_images = source_images.to(device)\n",
        "            source_labels = source_labels.to(device)\n",
        "\n",
        "            source_labels = torch.clamp(source_labels, 0, 9)\n",
        "\n",
        "            source_latent = generator(source_images)\n",
        "\n",
        "            outputs = source_classifier(source_latent)\n",
        "            loss = classification_loss(outputs, source_labels)\n",
        "\n",
        "            optimizer_SC.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_SC.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += source_labels.size(0)\n",
        "            correct += (predicted == source_labels).sum().item()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loop.set_postfix(loss=total_loss/total, accuracy=100*correct/total)\n",
        "\n",
        "    print(f\"Final Accuracy on Source Domain: {100*correct/total:.2f}%\")\n",
        "\n",
        "source_classifier = SourceClassifier(latent_dim=100, num_classes=10).to(device)\n",
        "train_source_classifier(dataloader_source, n_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHsPrjUM8eeN",
        "outputId": "cfea011e-f9a0-49cb-e205-cc5c2e6ee5db"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Source Classifier - Epoch [1/10]: 100%|██████████| 38/38 [00:33<00:00,  1.12it/s, accuracy=77.6, loss=0.0206]\n",
            "Train Source Classifier - Epoch [2/10]: 100%|██████████| 38/38 [00:34<00:00,  1.10it/s, accuracy=81.5, loss=0.0137]\n",
            "Train Source Classifier - Epoch [3/10]: 100%|██████████| 38/38 [00:33<00:00,  1.13it/s, accuracy=81.5, loss=0.0136]\n",
            "Train Source Classifier - Epoch [4/10]: 100%|██████████| 38/38 [00:33<00:00,  1.12it/s, accuracy=81.5, loss=0.0136]\n",
            "Train Source Classifier - Epoch [5/10]: 100%|██████████| 38/38 [00:33<00:00,  1.13it/s, accuracy=81.5, loss=0.0136]\n",
            "Train Source Classifier - Epoch [6/10]: 100%|██████████| 38/38 [00:34<00:00,  1.12it/s, accuracy=81.5, loss=0.0136]\n",
            "Train Source Classifier - Epoch [7/10]: 100%|██████████| 38/38 [00:33<00:00,  1.13it/s, accuracy=81.5, loss=0.0136]\n",
            "Train Source Classifier - Epoch [8/10]: 100%|██████████| 38/38 [00:34<00:00,  1.11it/s, accuracy=81.5, loss=0.0136]\n",
            "Train Source Classifier - Epoch [9/10]: 100%|██████████| 38/38 [00:33<00:00,  1.12it/s, accuracy=81.5, loss=0.0136]\n",
            "Train Source Classifier - Epoch [10/10]: 100%|██████████| 38/38 [00:34<00:00,  1.10it/s, accuracy=81.5, loss=0.0135]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy on Source Domain: 81.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_target(dataloader_target):\n",
        "    source_classifier.eval()\n",
        "    generator.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loop = tqdm(dataloader_target, total=len(dataloader_target))\n",
        "        loop.set_description(f\"Evaluating on Target Domain\")\n",
        "\n",
        "        for target_images, target_labels in loop:\n",
        "            target_images = target_images.to(device)\n",
        "            target_labels = target_labels.to(device)\n",
        "\n",
        "            target_latent = generator(target_images)\n",
        "\n",
        "            outputs = source_classifier(target_latent)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target_labels.size(0)\n",
        "            correct += (predicted == target_labels).sum().item()\n",
        "\n",
        "            loop.set_postfix(accuracy=100*correct/total)\n",
        "\n",
        "    print(f\"Final Accuracy on Target Domain: {100*correct/total:.2f}%\")\n",
        "\n",
        "evaluate_on_target(dataloader_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ud2G3Sh8eZl",
        "outputId": "067ed554-6b25-47c8-be02-6707f8b8ea75"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating on Target Domain: 100%|██████████| 69/69 [00:24<00:00,  2.84it/s, accuracy=2.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy on Target Domain: 2.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}